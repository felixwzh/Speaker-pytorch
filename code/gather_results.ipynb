{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gather results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we gather the training/dev/test and generated train/dev/test resutls for better analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sacrebleu\n",
    "import os\n",
    "from termcolor import colored, cprint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gather_data(data_file):\n",
    "    \"\"\"\n",
    "    return a dict of user.\n",
    "    each element is a list of src/tgt pair\n",
    "    \"\"\"\n",
    "    user_train_data={}\n",
    "    \n",
    "    \n",
    "    with open(data_file,'r') as fin:\n",
    "        lines=fin.readlines()\n",
    "        for line in lines:\n",
    "            src,tgt=line.strip().split('ï¿¨')\n",
    "            uid=int(tgt.split(' ')[0])\n",
    "            tgt_=tgt.split(' ')[1:]\n",
    "            tgt=''\n",
    "            for word in tgt_:\n",
    "                tgt+=word\n",
    "                tgt+=' '\n",
    "            tgt_sent=tgt[:-1]\n",
    "            \n",
    "            src_=src.split(' ')[1:]\n",
    "            src=''\n",
    "            for word in src_:\n",
    "                src+=word\n",
    "                src+=' '\n",
    "            src_sent=src[:-1]\n",
    "            src_tgt_pair={\n",
    "                'src':src_sent,\n",
    "                'tgt':tgt_sent\n",
    "            }\n",
    "            if uid not in user_train_data:\n",
    "                user_train_data[uid]=[]\n",
    "                \n",
    "            user_train_data[uid].append(src_tgt_pair)\n",
    "    return user_train_data\n",
    "            \n",
    "def gather_decode_data(data_file,ref_data):\n",
    "    decode_data=gather_data(data_file)\n",
    "    bleu = compute_bleu(ref_data,decode_data)\n",
    "    return {'data':decode_data,'bleu':bleu}\n",
    "# 4. showing results\n",
    "def display_one_user(user_train_data,user_ref_data,user_decode_data_list,user):\n",
    "    \"\"\"\n",
    "    a help function to display the decoded results of one user\n",
    "    \n",
    "    note that we have a user_decoded_data_list, \n",
    "    this is used for comparision for multiple decoded referrence\n",
    "    \"\"\"\n",
    "    # ['grey','red','green','yellow','blue','magenta','cyan','white']\n",
    "    color_list=['green','red','blue','magenta','cyan','white']\n",
    "    src_color='yellow'\n",
    "#     tgt_color=''\n",
    "    \n",
    "    # src_color\n",
    "    # 3. print the blue score\n",
    "    cprint('models\\' bleu: ','red',attrs=['reverse', 'blink'])    \n",
    "    for j in range(len(user_decode_data_list)):\n",
    "        cprint(user_decode_data_list[j]['bleu'],color_list[j])\n",
    "    cprint('user {}\\'s bleu: '.format(user),'red',attrs=['reverse', 'blink'])\n",
    "    for j in range(len(user_decode_data_list)):\n",
    "        score=compute_user_bleu(user_ref_data,user_decode_data_list[j]['data'],user)\n",
    "        cprint(score,color_list[j])\n",
    "    \n",
    "    \n",
    "    # 2. print the comparison\n",
    "    cprint('user {}\\'s decoded: '.format(user),'red',attrs=['reverse', 'blink'])\n",
    "    \n",
    "    pair_num=len(user_ref_data[user])\n",
    "    for i in range(pair_num):\n",
    "        # ref\n",
    "        cprint(user_ref_data[user][i]['src'],src_color)\n",
    "        print(user_ref_data[user][i]['tgt'])\n",
    "        for j in range(len(user_decode_data_list)):\n",
    "            cprint(user_decode_data_list[j]['data'][user][i]['tgt'],color_list[j])\n",
    "    \n",
    "    \n",
    "    # 1. get the train_data\n",
    "    cprint('user {}\\'s training data: '.format(user),'red',attrs=['reverse', 'blink'])\n",
    "    for pair in user_train_data[user]:\n",
    "        cprint(pair['src'],src_color)\n",
    "        print(pair['tgt'])\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "def gather_decode_file(output_file,mode):\n",
    "    decode_file='{}.txt'.format(mode)\n",
    "    ref_file='../data/src_data_full_feat_tf_resplited_review_50k/{}_ref.txt'.format(mode)\n",
    "    ref_data=gather_data(ref_file)\n",
    "    user_data_decode = gather_decode_data(output_file,ref_data)\n",
    "    print(output_file)\n",
    "    return user_data_decode\n",
    "\n",
    "def compute_bleu(ref_data,output_data):\n",
    "    ref=[]\n",
    "    output=[]\n",
    "    for user in ref_data:\n",
    "        ref_pairs=ref_data[user]\n",
    "        output_pairs=output_data[user]        \n",
    "        for pair in ref_pairs:\n",
    "            ref.append(pair['tgt'])\n",
    "        for pair in output_pairs:\n",
    "            output.append(pair['tgt'])\n",
    "    \n",
    "    bleu = sacrebleu.corpus_bleu(output, [ref])\n",
    "    return bleu.score\n",
    "def compute_user_bleu(ref_data,output_data,user):\n",
    "    ref=[]\n",
    "    output=[]\n",
    "    ref_pairs=ref_data[user]\n",
    "    output_pairs=output_data[user]        \n",
    "    for pair in ref_pairs:\n",
    "        ref.append(pair['tgt'])\n",
    "    for pair in output_pairs:\n",
    "        output.append(pair['tgt'])\n",
    "    \n",
    "    bleu = sacrebleu.corpus_bleu(output, [ref],force=True)\n",
    "    return bleu.score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. we gather the data in the training set for each user.\n",
    "train_data='../data/src_data_full_feat_tf_resplited_review_50k/train_ref.txt'\n",
    "user_train_data = gather_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. we gather the data in the test/dev set for each user.\n",
    "data_file='../data/src_data_full_feat_tf_resplited_review_50k/test_full_ref.txt'\n",
    "user_test_full_data = gather_data(data_file)\n",
    "data_file='../data/src_data_full_feat_tf_resplited_review_50k/val_full_ref.txt'\n",
    "user_val_full_data = gather_data(data_file)\n",
    "\n",
    "data_file='../data/src_data_full_feat_tf_resplited_review_50k/test_ref.txt'\n",
    "user_test_data = gather_data(data_file)\n",
    "data_file='../data/src_data_full_feat_tf_resplited_review_50k/val_ref.txt'\n",
    "user_val_data = gather_data(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../Speaker-pytorch/outputs/s_tf_512R280/test_full.txt_Speaker_model.best_18.txt\n",
      "../../Speaker-pytorch/outputs/s_tf_512R280/test_full.txt_Speaker_model.best_10.txt\n"
     ]
    }
   ],
   "source": [
    "# 3. we gather the results in test.\n",
    "folder='s_tf_512R280'\n",
    "save_prefix='model.best_' # ['model.best_','model.']\n",
    "num=18\n",
    "mode='test_full' # mode: [test,test_full,valid,valid_full]\n",
    "\n",
    "decode_18=gather_decode_file(folder,save_prefix,num,mode)\n",
    "num=10\n",
    "decode_10=gather_decode_file(folder,save_prefix,num,mode)\n",
    "\n",
    "\n",
    "# 3. we gather the results in test.\n",
    "folder='s_tf_512R280'\n",
    "save_prefix='model.best_' # ['model.best_','model.']\n",
    "num=18\n",
    "mode='test_full' # mode: [test,test_full,valid,valid_full]\n",
    "\n",
    "decode_18=gather_decode_file(folder,save_prefix,num,mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../Speaker-pytorch/outputs/s_tf_512R280/test_full.txt_Speaker_model.best_18.txt\n"
     ]
    }
   ],
   "source": [
    "mode='test_full' # mode: [test,test_full,valid,valid_full]\n",
    "output_file='../../Speaker-pytorch/outputs/s_tf_512R280/test_full.txt_Speaker_model.best_18.txt'\n",
    "s_tf_512R280_best_18=gather_decode_file(output_file,mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode='test_full' # mode: [test,test_full,valid,valid_full]\n",
    "output_file='../../Speaker-pytorch/outputs/s_tf_512R280/test_full.txt_Speaker_model.best_18.txt'\n",
    "s_tf_512R280_best_18=gather_decode_file(output_file,mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../DialoGPT/outputs/medium_10epochs_trial_2/test_full_ref.txt_step-12500.txt\n"
     ]
    }
   ],
   "source": [
    "mode='test_full'\n",
    "output_file='../../DialoGPT/outputs/medium_10epochs_trial_2/test_full_ref.txt_step-12500.txt'\n",
    "DialoGPT_medium_10epochs_trial_2_12500=gather_decode_file(output_file,mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display\n",
    "display_one_user(user_train_data=user_train_data,\n",
    "                 user_ref_data=user_test_full_data,\n",
    "                 user_decode_data_list=[s_tf_512R280_best_18,DialoGPT_medium_10epochs_trial_2_12500],\n",
    "                 user=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
